# Movielens
Feature extraction using simple Autoencoder

We often use ICA or PCA to extract features from the high-dimensional data. The autoencoder is
another interesting algorithm to achieve the same purpose in the context of Deep Learning.
With the purpose of learning a function to approximate the input data itself such that F(X) =
X, an autoencoder consists of two parts, namely encoder and decoder. While the encoder aims
to compress the original input data into a low-dimensional representation, the decoder tries to
reconstruct the original input data based on the low-dimension representation generated by the
encoder.

### Dataset 
[MovieLens 100k dataset](https://github.com/suhas2go/Movielens/blob/master/data)

### Implementation

We first use collaborative filtering - implicit characteristics based on similarity of usersâ€™ preferences
to those of other users to fill the ratings matrix (users x movies). Then this is inputed into the autoencoder which encodes and decodes the ratings, the layers in middle reduce the features to lower
dimension.

<p align="center"> 
<img src=https://github.com/suhas2go/Movielens/blob/master/res/autoencoder_img.jpg>
</p>

### Possible Improvements
 
 * Increase number of layers for gradual reduction of features.
 * Explore other variations of autoencoders. 
 
### References

> F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4, Article 19 (December 2015), 19 pages.
> -- <cite>[DOI][1]</cite>

[1]:http://dx.doi.org/10.1145/2827872


